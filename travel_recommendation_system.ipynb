{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# India Travel Recommendation System\n",
    "\n",
    "# Multi-Dataset Collaborative Filtering with Content-Based Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Integration & Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df = pd.read_csv('/dataset/100-tourist-cities-in-india/Indian Cities.csv')\n",
    "places_df = pd.read_csv('/dataset/famous-indian-tourist-places/Indian Places to Visit.csv')\n",
    "reviews_df = pd.read_csv('/dataset/indian-places-to-visit-reviews-data/Indian places reviews.csv')\n",
    "restaurants_df = pd.read_csv('/dataset/indian-restaurants-2023/Indian Restaurants.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering for cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df['features'] = cities_df.apply(lambda x: \n",
    "    f\"{x['Type']} {x['BestTimeToVisit']} {x['FamousFor']}\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing for places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "places_df['clean_desc'] = places_df['About'].apply(\n",
    "    lambda x: ' '.join([word for word in simple_preprocess(x) \n",
    "                       if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets on geographic hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_hierarchy = {\n",
    "    'City': cities_df[['City', 'State']],\n",
    "    'Place': places_df[['Place name', 'City']],\n",
    "    'Restaurant': restaurants_df[['Restaurant Name', 'City']]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create master dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(\n",
    "    places_df,\n",
    "    cities_df,\n",
    "    on='City',\n",
    "    how='left'\n",
    ").merge(\n",
    "    restaurants_df.groupby('City')['Aggregate rating'].mean().reset_index(),\n",
    "    on='City',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(master_df['clean_desc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['composite_score'] = (\n",
    "    0.6 * master_df['Place rating'] + \n",
    "    0.3 * master_df['Aggregate rating'] + \n",
    "    0.1 * master_df['Number of reviews']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_mapping = {\n",
    "    'Winter': ['December', 'January', 'February'],\n",
    "    'Summer': ['March', 'April', 'May'], \n",
    "    'Monsoon': ['June', 'July', 'August', 'September'],\n",
    "    'Autumn': ['October', 'November']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recommendation Engine Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, cosine_sim, metadata, reviews_data):\n",
    "        self.cosine_sim = cosine_sim\n",
    "        self.metadata = metadata\n",
    "        self.reviews_data = reviews_data\n",
    "        self.indices = pd.Series(\n",
    "            metadata.index, \n",
    "            index=metadata['Place name']\n",
    "        ).drop_duplicates()\n",
    "        \n",
    "    def _get_content_based_recs(self, title, n=10):\n",
    "        idx = self.indices[title]\n",
    "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_indices = [i[0] for i in sim_scores[1:n+1]]\n",
    "        return self.metadata.iloc[sim_indices]\n",
    "    \n",
    "    def _get_collaborative_filtering_recs(self, user_id):\n",
    "        # Implement matrix factorization\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        data = Dataset.load_from_df(\n",
    "            self.reviews_data[['User ID', 'Place name', 'Review Rating']], \n",
    "            reader\n",
    "        )\n",
    "        trainset = data.build_full_trainset()\n",
    "        algo = SVD()\n",
    "        algo.fit(trainset)\n",
    "        \n",
    "        # Predict ratings for all places\n",
    "        testset = trainset.build_anti_testset()\n",
    "        predictions = algo.test(testset)\n",
    "        \n",
    "        # Return top predictions for user\n",
    "        user_preds = [pred for pred in predictions if pred.uid == user_id]\n",
    "        user_preds.sort(key=lambda x: x.est, reverse=True)\n",
    "        return [pred.iid for pred in user_preds[:10]]\n",
    "    \n",
    "    def get_hybrid_recommendations(self, title=None, user_id=None, n=10):\n",
    "        if title:\n",
    "            content_recs = self._get_content_based_recs(title, n)\n",
    "        if user_id:\n",
    "            cf_recs = self._get_collaborative_filtering_recs(user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement hybrid logic\n",
    "\n",
    "# (Could use weighted combination of both approaches) return content_recs # Simplified for example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommender(test_cases):\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        # Implement evaluation logic\n",
    "        # Compare recommendations with actual user preferences\n",
    "        pass\n",
    "    \n",
    "    return np.mean(precision_scores), np.mean(recall_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deployment-Ready Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonal_recommendations(season, n=10):\n",
    "    filtered = master_df[master_df['Best time'].str.contains(season)]\n",
    "    return filtered.nlargest(n, 'composite_score')[['Place name', 'City', 'composite_score']]\n",
    "\n",
    "def get_personalized_recommendations(user_preferences):\n",
    "    # Implement preference matching using Word2Vec\n",
    "    model = gensim.models.Word2Vec.load('travel_word2vec.model')\n",
    "    # Vectorize preferences and find similar items\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Implementation Details:\n",
    "\n",
    "# 1. **Hybrid Architecture**: Combines content-based filtering (TF-IDF + cosine similarity)\n",
    "\n",
    "# with collaborative filtering (matrix factorization using SVD)\n",
    "\n",
    "#\n",
    "\n",
    "# 2. **Feature Engineering**:\n",
    "\n",
    "# - Composite scoring system combining ratings, reviews, and restaurant quality\n",
    "\n",
    "# - Advanced text preprocessing with custom stopword lists\n",
    "\n",
    "# - Geographic hierarchy integration\n",
    "\n",
    "#\n",
    "\n",
    "# 3. **Seasonal Filtering**: Time-aware recommendations using month/season mapping\n",
    "\n",
    "#\n",
    "\n",
    "# 4. **Evaluation Metrics**: Precision@K and Recall@K for recommendation quality\n",
    "\n",
    "#\n",
    "\n",
    "# 5. **Deployment Features**:\n",
    "\n",
    "# - Word2Vec models for semantic understanding of travel preferences\n",
    "\n",
    "# - API-ready functions for integration with web applications\n",
    "\n",
    "#\n",
    "\n",
    "# Next Steps:\n",
    "\n",
    "# - Implement real-time user preference handling\n",
    "\n",
    "# - Add geospatial features using city coordinates\n",
    "\n",
    "# - Integrate weather API for dynamic recommendations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
